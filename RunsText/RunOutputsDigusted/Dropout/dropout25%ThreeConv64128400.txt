Epoch 200
Batch Size 55
Learn Rate 0.005
Running on GPU
[1,   500] loss: 1.542
Accuracy of the network on the 10000 test images: 42 %
Highest Accurracy is 42 % from Epoch 1
[2,   500] loss: 1.286
Accuracy of the network on the 10000 test images: 48 %
Highest Accurracy is 48 % from Epoch 2
[3,   500] loss: 1.155
Accuracy of the network on the 10000 test images: 51 %
Highest Accurracy is 51 % from Epoch 3
[4,   500] loss: 1.041
Accuracy of the network on the 10000 test images: 51 %
Highest Accurracy is 51 % from Epoch 3
[5,   500] loss: 0.934
Accuracy of the network on the 10000 test images: 51 %
Highest Accurracy is 51 % from Epoch 3
[6,   500] loss: 0.827
Accuracy of the network on the 10000 test images: 52 %
Highest Accurracy is 52 % from Epoch 6
[7,   500] loss: 0.719
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[8,   500] loss: 0.616
Accuracy of the network on the 10000 test images: 52 %
Highest Accurracy is 53 % from Epoch 7
[9,   500] loss: 0.528
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[10,   500] loss: 0.459
Accuracy of the network on the 10000 test images: 52 %
Highest Accurracy is 53 % from Epoch 7
[11,   500] loss: 0.380
Accuracy of the network on the 10000 test images: 52 %
Highest Accurracy is 53 % from Epoch 7
[12,   500] loss: 0.331
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[13,   500] loss: 0.288
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[14,   500] loss: 0.251
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[15,   500] loss: 0.231
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[16,   500] loss: 0.196
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[17,   500] loss: 0.175
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 53 % from Epoch 7
[18,   500] loss: 0.156
Accuracy of the network on the 10000 test images: 54 %
Highest Accurracy is 54 % from Epoch 18
[19,   500] loss: 0.144
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 54 % from Epoch 18
[20,   500] loss: 0.137
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 54 % from Epoch 18
[21,   500] loss: 0.124
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 54 % from Epoch 18
[22,   500] loss: 0.114
Accuracy of the network on the 10000 test images: 54 %
Highest Accurracy is 54 % from Epoch 18
[23,   500] loss: 0.108
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 54 % from Epoch 18
[24,   500] loss: 0.100
Accuracy of the network on the 10000 test images: 54 %
Highest Accurracy is 54 % from Epoch 18
[25,   500] loss: 0.091
Accuracy of the network on the 10000 test images: 54 %
Highest Accurracy is 54 % from Epoch 18
[26,   500] loss: 0.081
Accuracy of the network on the 10000 test images: 53 %
Highest Accurracy is 54 % from Epoch 18
[27,   500] loss: 0.082

        self.conv1 = nn.Conv2d(3, 64, (3,3)) 
        self.batchnorm1 = nn.BatchNorm2d(64)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(64, 128, (3,3))
        self.batchnorm2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, (3,3))
        self.batchnorm3 = nn.BatchNorm2d(256)
        self.conv4 = nn.Conv2d(256, 512, (3,3))
        self.batchnorm4 = nn.BatchNorm2d(512)
        self.conv5 = nn.Conv2d(256, 512, (2,2))
        self.batchnorm5 = nn.BatchNorm2d(512)
        self.fc1 = nn.Linear(14400, 120)
        self.batchnormlin1 = nn.BatchNorm2d(120)
        self.fc2 = nn.Linear(120, 84)
        self.batchnormlin2 = nn.BatchNorm2d(84)
        self.fc3 = nn.Linear(84, 10)
        self.batchnormlin3 = nn.BatchNorm2d(10)
        self.dropout = nn.Dropout(0.25)
       
    
    def forward(self, x):
        x = self.pool(((F.relu(self.conv1(x)))))
        x = self.dropout(self.batchnorm1(x))
        x = self.pool(((F.relu(self.conv2(x)))))
        x = self.dropout(self.batchnorm2(x))
        x = self.pool(F.relu(self.conv3(x)))
        x = self.dropout(self.batchnorm3(x))
        #x = self.pool(F.relu(self.conv4(x)))
        #x = self.batchnorm4(x)
        #x = self.pool(F.relu(self.conv5(x)))
        #x = self.batchnorm5(x)
        x = torch.flatten(x, 1) # flatten all dimensi        ons except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x